{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Text analysis lies at the heart of many interesting and important machine learning problems today. These kinds of problems include things like text classification (determining which genre a novel belongs to), authorship attribution (determining which individual authored an unknown piece of text), spam detection (determining which emails are likely spam), and sentiment analysis (identifying the positive or negative tone attributed to a piece of text). Sentiment analysis in particular has gained a place of great importance in the business world in recent years, and for good reason - it can be a very profitable endeavor!\n",
    "\n",
    "With the continued rise in popularity of social media like Facebook, Twitter, and Instagram over the last decade, businesses have gained access to enormous amounts of potentially profitable data that have never been available before to any previous generation. Twitter, in particular, has been instrumental in allowing businesses to interact directly with their customers and new consumers around the world in real time. As such, sentiment analysis can allow businesses to quickly identify and understand consumer attitude toward particular products, marketing strategies, etc., without the arduous task of directly polling many thousands of individuals. Analyzing consumer sentiment relating to certain goods can give businesses a competitive advantage over their rivals, allowing them to quickly identify new products that may be well-received, or pin-pointing possible improvements on existing products, thereby increasing profits significantly.\n",
    "\n",
    "In this post I develop and detail an algorithm to identify the sentiment of tweets sent by U.S. airline travelers. This algorithm follows a naive Bayes approach under a \"bag of words\" assumption. I find that the classifier works quite well, correctly identifying tweet sentiment about 87% of the time.\n",
    "\n",
    "Before we take a look at the code, let's go through a brief introduction of Naive Bayes classification and see how we can use it to identify tweet sentiment.\n",
    "\n",
    "# Naive Bayes Classification\n",
    "\n",
    "In this post, we are interested in classifying the sentiment of tweets sent by U.S. airline travelers. The sentiment of a tweet refers to the \"tone\" or \"feelings\" associated with the text. Sentiment can be classified as being either positive, negative, or neutral. An example tweet for each of these cases is given below.\n",
    "\n",
    "* Positive: What a great flight. I had a lot of fun!\n",
    "* Negative: Awful service. Flight was delayed again.\n",
    "* Neutral: Leaving Las Angeles in one hour.\n",
    "\n",
    "The first tweet (positive) conveys the feeling that the sender is happy and has had a good traveling experience, while the second tweet (negative) conveys a feeling of anger or dissatisfaction with the airline service. The third tweet (neutral) conveys no sentiment; there is no identifiable positive or negative feeling or tone associated with it. To keep things simple, we will only be interested in binary classification in this post — that is, classifying sentiment as being either \"positive\" or \"negative\". To categorize these tweets, we'll be using something called a naive Bayes classifier.\n",
    "\n",
    "The naive Bayes classifier relies on the Bayesian approach of conditional probabilities. The Bayesian approach to computing probabilities is based on Bayes' theorem, which can be stated mathematically as\n",
    "\n",
    "$$P(A\\vert B) = \\frac{P(B\\vert A)P(A)}{P(B)},$$\n",
    "\n",
    "where A and B are two different events. From [this](https://en.wikipedia.org/wiki/Bayes'_theorem#Examples) source,\n",
    "\n",
    "* $P(A)$ and $P(B)$ are the probabilities of observing events A and B without regard to each other.\n",
    "* $P(A\\vert B)$, a conditional probability, is the probability of observing event A given that B is true.\n",
    "* $P(B\\vert A)$ is the probability of observing event B given that A is true.\n",
    "\n",
    "As described above, the Bayesian approach is conditional in the sense that probabilities are computed based on \"degrees of belief\" of certain occurrences that contribute to a final probability we're trying to compute. For example, the U.S. has a population of about 320 million people at the present time. If we are told that 32 million people currently living in the U.S. will be diagnosed with cancer at some point in their lives, we might expect our own chances of developing cancer at some point are 10%. However, such a simple calculation does not take into account several important factors which may lead to a better probability estimate. For example, what if some people are smokers? What if some people do not exercise reagularly, or are generally unhealthy? As a toy example, let's compute the probability of an individual being diagnosed with cancer given that they smoke regularly. In this case, the terms in the equation above would be\n",
    "\n",
    "* $P(A\\vert B)$, the probability of getting cancer (event A) given that an individual is a smoker (event B).\n",
    "* $P(B\\vert A)$, the probability that an individual diagnosed with cancer is a smoker.\n",
    "* $P(A)$, the probability of anyone (smoker or not) being diagnosed with cancer.\n",
    "* $P(B)$, the probability that an individual is a smoker.\n",
    "\n",
    "For this example, let's suppose that the probability that an individual diagnosed with cancer is a smoker is 60%, and that 20% of the U.S. population are smokers. We then compute the probability of a smoker being diagnosed with cancer as\n",
    "\n",
    "$$P(cancer\\vert smoker) = \\frac{P(smoker\\vert cancer)P(cancer)}{P(smoker)} = \\frac{0.6\\times0.1}{0.2} = 30\\%,$$\n",
    "\n",
    "or triple the population cancer diagnosis probability of 10%. Of course this is a very simple example, but hopefully it gets the point across.\n",
    "\n",
    "The \"naive\" part of the naive Bayes classifier comes from the assumption that features describing a particular object are independent of one another. For example, say you had a set of unlabeled animals that you wanted to classify as either being a chicken or a horse. Each animal has two defining features that one could use to classify them — weight and color. Here, it's safe to assume that the weight feature is independent of the color feature, and vice versa. In other words, the weight of an animal has no bearing on what its color might be, and its color has no bearing on how much the animal weighs. Of course this is a simple example, and the relationship between multiple variables in a real life classification situation is not always so clear-cut.\n",
    "\n",
    "In classifying tweet text, we will be relying on a \"bag of words\" approach. This means that we treat all tweets of a given labeled class as being a giant unordered group (or \"bag\") of words. When presented with an unlabeled tweet to classify, we will look at its individual words and compare the number of times they occur in the \"positive\" bag to the number times they occur in the \"negative\" bag. If the words occur more often in the positive bag, we simply label the tweet sentiment as being \"positive\", while if they occur more often in the negative bag, the tweet is labeled as being \"negative\". In other words, we are interested only in word frequency in our classification. To compute the probability of a tweet belonging to a particular class $c$, we take Bayes' theorem and rewrite it as\n",
    "\n",
    "$$\\hat{c} = \\mathrm{argmax_{c}} \\frac{P(t\\vert c)P(c)}{P(t)}.$$\n",
    "\n",
    "We can also make the simplification that $P(t\\vert c)$, the probability of tweet $t$ being in class $c$, can be represented by the probability of its individual words being in $c$. Mathematically, this can be written as\n",
    "\n",
    "$$P(t\\vert c) = P(w_1\\vert c) \\cdot P(w_2\\vert c) \\cdot \\ldots \\cdot P(w_n\\vert c),$$\n",
    "\n",
    "where $w_i$ is the $i^{\\rm{th}}$ word in the tweet, and $n$ is the total number of words in the tweet. Combining the last two equations, we get\n",
    "\n",
    "$$\\hat{c} = \\mathrm{argmax_{c}} P(c)\\big[P(w_1\\vert c) \\cdot P(w_2\\vert c) \\cdot \\ldots \\cdot P(w_n\\vert c)\\big].$$\n",
    "\n",
    "Or, more compactly,\n",
    "\n",
    "$$\\hat{c} = \\mathrm{argmax_{c}} P(c) \\prod_{i=1}^{n} P(w_i\\vert c).$$\n",
    "\n",
    "# Training the Classifier\n",
    "\n",
    "Okay, now that we have the procedure written down mathematically, let's put everything together and describe how to train the classifier. In order to compute $\\hat{c}$ for an unlabeled tweet, we need to compute the two terms $P(c)$ and\n",
    "\n",
    "$$\\prod_{i=1}^{n} P(w_i\\vert c).$$\n",
    "\n",
    "To compute the \"prior\", $P(c)$, we simply have to compute the fraction of tweets in our training set that are of class $c$. This can be written as\n",
    "\n",
    "$$P(c) = \\frac{N_c}{N_t},$$\n",
    "\n",
    "where $N_c$ is the number of tweets of class $c$, and $N_t$ is the total number of tweets in the training set. To find the term\n",
    "\n",
    "$$\\prod_{i=1}^{n} P(w_i\\vert c),$$\n",
    "\n",
    "we have to compute $P(w_i\\vert c)$, the frequency of word $w_i$ in class $c$. To do this, we calculate\n",
    "\n",
    "$$P(w_i\\vert c) = \\frac{count(w_i,c)}{\\sum_v count(w,c)}.$$\n",
    "\n",
    "In this equation, the numerator represents the number of times word $w_i$ appears in class $c$, and the denominator represents the total number of words in $c$. In some cases, we'll find that a new unclassified tweet contains a word that is not in the training set at all. In that case the numerator goes to zero, and since our method dictates that we multiply individual word probabilitites together, the overall probability of a tweet being in class $c$ automatically goes to zero. To get around this, we can introduce a Laplace smoothing factor so that even if a word is not contained in class $c$, we can still compute a non-zero probability value. We therefore modify the above equation to look like\n",
    "\n",
    "$$P(w_i\\vert c) = \\frac{count(w_i,c)+1}{\\sum_v count(w,c)+N_v}.$$\n",
    "\n",
    "Notice that even if $count(w_i,c)$ is zero, the $+1$ term keeps $P(w_i\\vert c)$ from going to zero. The denominator also contains a new term, $N_v$. This is called the vocabulary &#8212; the number of unique words in the full training set. So to summarize, before we can classify a new tweet, we need to train the classifier. During the training procedure, we must compute\n",
    "\n",
    "* The priors, $P(c)$, for each class $c$.\n",
    "* The list of all words in each class $c$.\n",
    "* The number of unique words in the training set (the vocabulary).\n",
    "\n",
    "Okay, now that we have some understanding of how the classifier works, we can go on and explore the data!\n",
    "\n",
    "# Tweet Data\n",
    "\n",
    "Let's start by loading in the appropriate Python libraries and reading in the tweet data. We then grab only data columns *text* and *airline_sentiment*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as mp\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "tweets = pd.read_csv('/Users/degrave/DataScience/site/sentiment/twitter-airline-sentiment/Tweets.csv')\n",
    "\n",
    "df = tweets[['airline_sentiment','text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by taking a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the data contain information regarding the the names of various U.S. airline companies, the text contained in each user's tweet, tweet sentiment (postive, negative, or neutral), the reason for any negative sentiment toward a particular airline, user location where available, etc. Here, we will try and identify tweet sentiment based solely on the text of the tweet, ignoring all other data columns.\n",
    "\n",
    "At the moment, the full set of 14,640 tweets is comprised of 2,363 positive ones, 9,178 negative ones, and 3,099 neutral ones. The code snippet belows allows us to define the number of different classes we'll divide the tweets into. In this particular post, we are only interested in binary classification; in other words classifying tweets as either positive or negative, ignoring the neutral ones. We therefore set n_class = 2. We can also define the number of tweets per class we'll use in our training set. If the classes have a very different number of tweets (i.e., the classes are imbalanced) it is often the case that the algorithm will learn that always guessing the more prevalent class (the negative class in our case) is a good thing to do, and will subsequently misclassify many of the positive instances. Because the positive and negative classes are imbalanced in our case, we'll downsample the negative class to be the same size as the positive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(df, nclass):\n",
    "    if nclass == 2:\n",
    "        df_pos = df[df['airline_sentiment'] == 'positive']\n",
    "        df_neg = df[df['airline_sentiment'] == 'negative'].sample(n=len(df_pos), random_state=0)\n",
    "\n",
    "        df = pd.concat([df_pos, df_neg], ignore_index=True).reset_index(drop=True)\n",
    "        #df['airline_sentiment'].replace('positive', 0, inplace=True)\n",
    "        #df['airline_sentiment'].replace('negative', 1, inplace=True)\n",
    "\n",
    "    elif nclass == 3:\n",
    "        df_pos = df[df['airline_sentiment'] == 'positive']\n",
    "        df_neg = df[df['airline_sentiment'] == 'negative'].sample(n=len(df_pos), random_state=0)\n",
    "        df_neu = df[df['airline_sentiment'] == 'neutral'].sample(n=len(df_pos), random_state=0)\n",
    "\n",
    "        df = pd.concat([df_pos, df_neg, df_neu], ignore_index=True).reset_index(drop=True)\n",
    "        #df['airline_sentiment'].replace('positive', 0, inplace=True)\n",
    "        #df['airline_sentiment'].replace('negative', 1, inplace=True)\n",
    "        #df['airline_sentiment'].replace('negative', 1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df = getData(df, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Data\n",
    "\n",
    "Before we can start classifying tweets, we first need to clean them up a little bit. One may note that tweets in their raw form can be quite messy; they contain several forms of punctuation, capitalizations, url links, etc. Remember, we are only interested in looking at specific words and their usage here, so these things matter to us. To this end, we can define a couple of functions that we'll use to process all the tweets in our dataset. The first function, processText, takes in a tweet and strips away all punctuation, special characters, and extra white space. It also replaces any instance of *www* or *http* with the term *urlsite*, and makes all words lowercase.\n",
    "\n",
    "The second function, rmStopWords, removes stop words from each tweet. Stop words are words that, even though they're common in speech, really don't convey any sentiment or feeling. These include words like \"at\", \"and\", \"the\", etc. The function splits a tweet into its individual word tokens and checks to see if any of the words are in a pre-defined stop word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processText(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\r', ' ', text)\n",
    "    text = re.sub('((www\\S+)|(http\\S+))', 'urlsite', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    text = re.sub('[\\W]+', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def rmStopWords(text):\n",
    "    text = [i for i in text.split() if i not in stop]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our tweets through the two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['textPro'] = df['text'].apply(processText).apply(rmStopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>textPro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus added commercials experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>virginamerica yes nearly every time fly vx ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n",
       "      <td>virginamerica well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>virginamerica amazing arrived hour early good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>virginamerica lt 3 pretty graphics much better...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1          positive  @VirginAmerica yes, nearly every time I fly VX...   \n",
       "2          positive    @virginamerica Well, I didn't…but NOW I DO! :-D   \n",
       "3          positive  @VirginAmerica it was amazing, and arrived an ...   \n",
       "4          positive  @VirginAmerica I &lt;3 pretty graphics. so muc...   \n",
       "\n",
       "                                             textPro  \n",
       "0  virginamerica plus added commercials experienc...  \n",
       "1  virginamerica yes nearly every time fly vx ear...  \n",
       "2                                 virginamerica well  \n",
       "3      virginamerica amazing arrived hour early good  \n",
       "4  virginamerica lt 3 pretty graphics much better...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been processed, we have to split it up into separate training and test sets. Generally, for a given set of data, about two thirds is randomly chosen and placed in the training set, while the other one third is reserved for the test set. Since our tweet dataset isn't very large, we'll use an 80-20 split instead. Fortunately for us, Python's Scikit-Learn package has a nice built-in method called *train_test_split* that allows us to divide the data in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Tweet Classifier\n",
    "Okay, now the fun part! Below we define our own Python class called TweetNBClassifier which allows us to fit the classifier on our training data, predict the sentiment of each tweet (positive or negative), and score our results (i.e., determine how many tweets we've classified correctly). The class works sort of like a container for the various functions we'll need. We'll go through each section of the classifier and describe what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetNBClassifier:\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.df_pos = X[X['airline_sentiment'] == 'positive']\n",
    "        self.df_neg = X[X['airline_sentiment'] == 'negative']\n",
    "        self.df_neu = X[X['airline_sentiment'] == 'neutral']\n",
    "\n",
    "        Pr_pos = self.df_pos.shape[0]/X.shape[0]\n",
    "        Pr_neg = self.df_neg.shape[0]/X.shape[0]\n",
    "        Pr_neu = self.df_neu.shape[0]/X.shape[0]\n",
    "        self.Prior  = (Pr_pos, Pr_neg, Pr_neu)\n",
    "\n",
    "        self.pos_words = ' '.join(self.df_pos['text']).split()\n",
    "        self.neg_words = ' '.join(self.df_neg['text']).split()\n",
    "        self.neu_words = ' '.join(self.df_neu['text']).split()\n",
    "\n",
    "        all_words = ' '.join(X['text'].tolist()).split()\n",
    "\n",
    "        self.vocab = len(Counter(all_words))\n",
    "\n",
    "        wc_pos = len(' '.join(self.df_pos['text']).split())\n",
    "        wc_neg = len(' '.join(self.df_neg['text']).split())\n",
    "        wc_neu = len(' '.join(self.df_neu['text']).split())\n",
    "        self.word_count = (wc_pos, wc_neg, wc_neu)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        class_choice = ['positive', 'negative', 'neutral']\n",
    "\n",
    "        classification = []\n",
    "        for tweet in X['text']:\n",
    "            text = tweet.split()\n",
    "\n",
    "            val_pos = np.array([])\n",
    "            val_neg = np.array([])\n",
    "            val_neu = np.array([])\n",
    "            for word in text:\n",
    "                tmp_pos = np.log(self.pos_words.count(word)+1)\n",
    "                tmp_neg = np.log(self.neg_words.count(word)+1)\n",
    "                tmp_neu = np.log(self.neu_words.count(word)+1)\n",
    "                val_pos = np.append(val_pos, tmp_pos)\n",
    "                val_neg = np.append(val_neg, tmp_neg)\n",
    "                val_neu = np.append(val_neu, tmp_neu)\n",
    "\n",
    "            denom_pos = len(text)*np.log(self.word_count[0]+self.vocab)\n",
    "            denom_neg = len(text)*np.log(self.word_count[1]+self.vocab)\n",
    "            denom_neu = len(text)*np.log(self.word_count[2]+self.vocab)\n",
    "\n",
    "            val_pos = np.log(self.Prior[0]) + np.sum(val_pos) - denom_pos\n",
    "            val_neg = np.log(self.Prior[1]) + np.sum(val_neg) - denom_neg\n",
    "            val_neu = np.log(self.Prior[2]) + np.sum(val_neu) - denom_neu\n",
    "\n",
    "            probability = (val_pos, val_neg, val_neu)\n",
    "            classification.append(class_choice[np.argmax(probability)])\n",
    "        return classification\n",
    "\n",
    "    def score(self, feature, target):\n",
    "        comp_c, comp_i = (0,0)\n",
    "        tp, tn, fp, fn = (0,0,0,0)\n",
    "\n",
    "        for i in range(0,len(feature)):\n",
    "            if feature[i] == target[i]:\n",
    "                comp_c += 1\n",
    "                if (target[i] == 'positive') & (feature[i] == 'positive'): tp += 1\n",
    "            else:\n",
    "                comp_i += 1\n",
    "                if (target[i] == 'positive') & (feature[i] == 'negative'): fn += 1\n",
    "                if (target[i] == 'negative') & (feature[i] == 'positive'): fp += 1\n",
    "\n",
    "        accuracy = comp_c/(comp_c + comp_i)\n",
    "        precision = tp/(tp + fp)\n",
    "        recall = tp/(tp + fn)\n",
    "        return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once instantiated, the TweetNBClassifier *fit* function takes in only one argument when called - the training dataset. The *fit* function proceeds to create variables that will be used in it and the *predict* and *score* functions below it. The training dataset is divided into separate dataframes for the positive, negative, and neutral tweets. Since we're only interested in doing a binary classification here, the dataframe neutral-tweet dataframe is empty.\n",
    "\n",
    "The first few lines of the fit function compute the Bayesian prior probabilities necessary for classification as described in the section above (i.e., the number of tweets in each class divided by the total number of tweets in the training set). Directly below this, we compute the number of words in each of the positive, negative, and neutral dataframes. Variable *all_words* collects every word in the training set, while variable *vocab* finds the number of <i>unique</i> words. This is referred to as the \"vocabulary\" of the data. Lastly, *wc_pos*, *wc_neg*, and *wc_neu* count the total number of words in the three dataframes.\n",
    "\n",
    "The predict function loops through all tweets in our test dataset, and uses the fit values computed above to predict which class each belongs to. To do this, each tweet is first split into its individual word components and, for each word in the tweet, we compute the fractions\n",
    "\n",
    "$$P(w_i\\vert c) = \\log \\Big[ \\frac{count(w_i,c)+1}{\\sum_{w\\in V}count(w,c) + |V|} \\Big]$$\n",
    "\n",
    "and add them together. Whichever class has the larger probability is then chosen as the predicted class. A nice worked example of this procedure can be found [here](https://web.stanford.edu/~jurafsky/slp3/6.pdf).\n",
    "\n",
    "Lastly, the score function scores our results in terms of how many tweets we classify correctly. To do this, we loop over each of the classification labels that our algorithm has produced, and compare them to the known labels of the test data. The fraction of correct tweets is then given as our accuracy score.\n",
    "\n",
    "Okay, let's run the classifier and see how well we do on our test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnb = TweetNBClassifier()\n",
    "tnb = tnb.fit(Xtr)\n",
    "\n",
    "predict = tnb.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8699788583509513\n",
      "precision: 0.8901345291479821\n",
      "recall: 0.8428874734607219\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall = tnb.score(predict, Xte['airline_sentiment'].tolist())\n",
    "\n",
    "print('accuracy:', accuracy)\n",
    "print('precision:', precision)\n",
    "print('recall:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the model, we see that the score function outputs three values. The first value is the accuracy score which suggests that we are able to correctly classify U.S. Airline tweet sentiment approximately 87% of the time! Not bad at all! The other two values refer to the precision and recall respectively. These terms will be discussed in more detail below. Let's first take a look at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(Xte['airline_sentiment'], predict)\n",
    "cm = cm.astype('float')/cm.sum(axis=1)\n",
    "\n",
    "fig, ax = mp.subplots(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', cbar=False);\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.xaxis.tick_top()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that the false positive and false negative rates are, as we had hoped, fairly small. We see, too, that the false negative rate is quite a bit larger than the false positive rate, meaning that we more often label a positive tweet as having negative sentiment. Perhaps the negative tweets contain more highly descriptive words like \"awful\", \"hate\", \"angry\", etc., so that our algorithm is able to more easily classify them.\n",
    "\n",
    "Let's now describe what precision and recall are using the description of a confusion matrix shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/degravek/notebooks/blob/master/images/confusionmatrix.png?raw=true\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x-axis of the table represents all of the tweets our algorithm predicted to be either positive or negative, while the y-axis represents all of the tweets in our test dataset with *actual* positive or negative labels. Inside the table, we see the terms \"true positive\", \"false positive\", \"true negative\", and \"false negative\". These are defined as\n",
    "\n",
    "* True positive: Tweets that our algorithm correctly classified as having positive sentiment.\n",
    "* False positive: Tweets that our algorithm incorrectly identified as having positive sentiment.\n",
    "* True negative: Tweets that our algorithm correctly classified as having negative sentiment.\n",
    "* False negative: Tweets that our algorithm incorrectly identified as having negative sentiment.\n",
    "\n",
    "So, in our case, precision refers to the fraction of tweets that our algorithm classified as positive which were in fact actually positive according to the labels in the test dataset. In other words, of all the tweets classified as being positive, how many of these were actually correct? Precision is computed as\n",
    "\n",
    "$$\\rm{Precision} = \\frac{true\\,positives}{true\\,positives + false\\,positives} = 89\\%.$$\n",
    "\n",
    "Similarly, recall answers the question \"of all of the positive tweets in the test set, how many did we classify correctly?\" Recall is computed as\n",
    "\n",
    "$$\\rm{Recall} = \\frac{true\\,positives}{true\\,positives + false\\,negatives} = 84\\%.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluding Remarks\n",
    "\n",
    "In this post we took a detailed look at the simple, yet powerful Naive Bayes classifier, and developed an algorithm to accurately classify the sentiment of U.S. Airline tweets. We found that the classifier correctly identified tweet sentiment about 87% of the time. However, there are still several improvements we could make to this algorithm. Text classification performance can sometimes be improved by using a \"binary approach\" - in other words, simply looking at whether or not a word exists in a tweet rather than its frequency (the number of times it's used). We could also adapt the algorithm to account for negation, which is often observed in real speech. For example, the tweet \"That flight was really bad\" has a different sentiment than \"That flight was really not that bad\". Additionally, in terms of examining how well the code generalizes, we could include a way to perform cross-validation to check that our accuracy, precision, and recall will hold up when presented with new, unseen data.\n",
    "\n",
    "Well, that's all I have for now. Thanks for following along!\n",
    "\n",
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
